{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c53caa2b-47a0-4d61-be43-b8ea7738cc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, roc_curve, auc, confusion_matrix, ConfusionMatrixDisplay, precision_recall_curve, average_precision_score\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "08cfddb9-bae1-467e-9ec0-e4c356d7478a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ==== Paramètres BERT ====\n",
    "MODEL_NAME = \"emilyalsentzer/Bio_ClinicalBERT\" # ou \"bert-base-uncased\" si indisponible\n",
    "MAX_LEN = 128\n",
    "EPOCHS = 3\n",
    "BATCH_SIZE = 8\n",
    "SEED = 42\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a0ae4579-5622-46c6-8010-90f703ef6e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== Extraction âge ====\n",
    "def extract_age(text):\n",
    "    if not isinstance(text, str):\n",
    "        return -1\n",
    "    mapping = {'newborn': 0.1, 'infant': 0.5, 'toddler': 2, 'child': 7, 'adolescent': 15, 'teenager': 15}\n",
    "    decades = {\"twenties\": 25, \"thirties\": 35, \"forties\": 45, \"fifties\": 55, \"sixties\": 65, \"seventies\": 75, \"eighties\": 85, \"nineties\": 95}\n",
    "    patterns = [\n",
    "        r'\\bI\\s*am\\s*(\\d{1,3})\\b', r\"\\bI'm\\s*(\\d{1,3})\\b\", r'\\bI\\s*am\\s*(\\d{1,3})\\s*yrs?\\b', r\"\\bI'm\\s*(\\d{1,3})\\s*yrs?\\b\",\n",
    "        r'\\b(\\d{1,3})\\s*(years? old|yrs? old|yr old|yo|ans?)\\b', r'\\b(\\d{1,3})\\s*-\\s*year[- ]*old\\b',\n",
    "        r'\\b(\\d{1,3})\\s?(?:M|F|m|f)[, ]', r'\\b(age|âge|Age|Âge)\\s*:?[\\s]*?(\\d{1,3})\\b',\n",
    "        r'\\b(\\d{1,3})\\s*[.,]', r'\\bmy\\s+\\d{1,3}-year-old', r'\\b(\\d{1,3})\\b(?=\\s*[-]*year[- ]*old)',\n",
    "        r'\\baged\\s*(\\d{1,3})\\b', r'\\bwhen I was (\\d{1,3})\\s*yrs?\\b']\n",
    "    for pat in patterns:\n",
    "        match = re.search(pat, text, re.IGNORECASE)\n",
    "        if match:\n",
    "            for group in match.groups():\n",
    "                if group and group.isdigit():\n",
    "                    return int(group)\n",
    "            if match.lastindex and match.lastindex >= 2 and match.group(2).isdigit():\n",
    "                return int(match.group(2))\n",
    "    match = re.search(r'\\b([a-z]+)\\s+year[s]? old\\b', text.lower())\n",
    "    if match:\n",
    "        words2num = {'zero': 0, 'one': 1, 'two':2, 'three':3, 'four':4, 'five':5, 'six':6, 'seven':7, 'eight':8,\n",
    "            'nine':9, 'ten':10, 'eleven':11, 'twelve':12, 'thirteen':13, 'fourteen':14, 'fifteen':15, \n",
    "            'sixteen':16, 'seventeen':17, 'eighteen':18, 'nineteen':19, 'twenty':20}\n",
    "        val = match.group(1)\n",
    "        if val in words2num:\n",
    "            return words2num[val]\n",
    "    match = re.search(r'(\\d{1,2})\\s*(months?|mos?|mo\\.?)\\s*(old)?\\b', text, re.IGNORECASE)\n",
    "    if match:\n",
    "        mois = int(match.group(1))\n",
    "        return round(mois / 12, 2)\n",
    "    relatives = [\n",
    "        'daughter', 'son', 'wife', 'mother[- ]in[- ]law', 'father[- ]in[- ]law', 'husband',\n",
    "        'mother', 'father', 'sister', 'brother'\n",
    "    ]\n",
    "    rel_pat = r'\\bmy\\s+(?:' + '|'.join(relatives) + r')\\s*(?:is|aged)?\\s*([\\d]{1,3})\\b'\n",
    "    match = re.search(rel_pat, text, re.IGNORECASE)\n",
    "    if match:\n",
    "        return int(match.group(1))\n",
    "    match = re.search(r'in\\s+(?:his|her|their)?\\s*(twenties|thirties|forties|fifties|sixties|seventies|eighties|nineties)\\b', text.lower())\n",
    "    if match:\n",
    "        return decades[match.group(1)]\n",
    "    match = re.search(r'(\\w+) and a half years?', text.lower())\n",
    "    if match:\n",
    "        words = {'one': 1, 'two': 2, 'three': 3, 'four': 4, 'five': 5, 'six': 6, 'seven': 7, 'eight': 8, 'nine': 9, 'ten': 10}\n",
    "        val = match.group(1)\n",
    "        if val in words:\n",
    "            return words[val] + 0.5\n",
    "    for label, val in mapping.items():\n",
    "        if label in text.lower():\n",
    "            return val\n",
    "    return -1\n",
    "\n",
    "# ==== Extraction sexe ====\n",
    "def extract_sex(text):\n",
    "    t = text.lower()\n",
    "    if re.search(r'\\bmale\\b|\\bman\\b|\\bm\\b|\\bboy\\b|\\bson\\b|\\bhusband\\b|\\bhe\\b|\\bhis\\b|\\bprostate\\b|\\bpenis\\b|\\btesticle\\b|\\bgentleman\\b|\\bdad\\b|\\bfather\\b|(semen|sperm|testical|motility|penis|testicles)', t, re.I):\n",
    "        return 'M'\n",
    "    elif re.search(r'\\bfemale\\b|\\bwoman\\b|\\bf\\b|\\bgirl\\b|\\bdaughter\\b|\\bwife\\b|\\bshe\\b|\\bher\\b|\\bpregnant\\b|\\bvagina\\b|\\buterus\\b|\\bovary\\b|\\bmenstruation\\b|\\bmother\\b|(pregnan|embryo|IVF|fetal|delivery|uterus|ovary|menstruation|period|girlfriend|wife|partner is pregnant|married woman|dysmenorrhea)', t, re.I):\n",
    "        return 'F'\n",
    "    if re.search(r'(sexual dysfunction|semen analysis|sperm count|erectile dysfunction|testosterone|gynecomastia|foreskin|errection|scrotum|testicle|sack|my brother)', t):\n",
    "        return 'M'\n",
    "    if re.search(r'(fertility treatment|fetal|fetus|oocyte|embryo transfer|gestational|insémination|dysmenorrhea|menstruation|vaginal|cervix|ovary|uterine|period|breast|menopause|ivf|iui|endometrio|cervix|pregnan|period|contraceptive|pregnancy|labia|pcos)|my sister', t):\n",
    "        return 'F'\n",
    "    return 'U'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2a1ed2bc-3d4a-4ae7-b123-bcf1705d4893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sex\n",
      "U    21876\n",
      "M    14082\n",
      "F     8947\n",
      "Name: count, dtype: int64\n",
      "\n",
      "RATIO (%) :\n",
      "F: 8947 (19.9%)\n",
      "M: 14082 (31.4%)\n",
      "U: 21876 (48.7%)\n",
      "Taux de lignes avec âge détecté : 44905 / 44905 = 100.0%\n"
     ]
    }
   ],
   "source": [
    "# ==== Chargement et extraction ====\n",
    "df = pd.read_csv(\"/Users/ines/NLP/emergency_chatbot/data/triage_dataset_preprocess.csv\", encoding=\"utf8\")\n",
    "df['age'] = df['question'].apply(extract_age)\n",
    "df['sex'] = df['question'].apply(extract_sex)\n",
    "df['label'] = df['triage'].map({'non-urgent': 0, 'urgent': 1})\n",
    "\n",
    "df['age'] = df['age'].replace(-1, np.nan)\n",
    "df['age'] = df['age'].fillna(df['age'].median())\n",
    "df['sex'] = df['sex'].fillna('U')\n",
    "\n",
    "counts = df['sex'].value_counts()\n",
    "total = len(df)\n",
    "print(counts)\n",
    "print(\"\\nRATIO (%) :\")\n",
    "for cat in ['F', 'M', 'U']:\n",
    "    pct = 100 * counts.get(cat, 0) / total\n",
    "    print(f\"{cat}: {counts.get(cat, 0)} ({pct:.1f}%)\")\n",
    "\n",
    "nb_age_detected = (df['age'] != -1).sum()\n",
    "nb_total = len(df)\n",
    "taux_age = nb_age_detected / nb_total * 100\n",
    "print(f\"Taux de lignes avec âge détecté : {nb_age_detected} / {nb_total} = {taux_age:.1f}%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6610c722-de25-4d40-8429-9f7098298e2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>triage</th>\n",
       "      <th>question_clean</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I am 35 years old unmarried , i was diagonized...</td>\n",
       "      <td>non-urgent</td>\n",
       "      <td>35 year old unmarried diagonize hepatitis b su...</td>\n",
       "      <td>35.0</td>\n",
       "      <td>U</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I have been having abdominal pain and burning ...</td>\n",
       "      <td>non-urgent</td>\n",
       "      <td>abdominal pain burn no relieve omeprazole bowe...</td>\n",
       "      <td>22.0</td>\n",
       "      <td>U</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sir, Day before yesterday i had an oil fried i...</td>\n",
       "      <td>urgent</td>\n",
       "      <td>sir day yesterday oil fry item snack chappathi...</td>\n",
       "      <td>22.0</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>friend has a lump where their coccyx is, has b...</td>\n",
       "      <td>urgent</td>\n",
       "      <td>friend lump coccyx complete agony literally sc...</td>\n",
       "      <td>22.0</td>\n",
       "      <td>U</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Which demographic should raise suspicion of a ...</td>\n",
       "      <td>non-urgent</td>\n",
       "      <td>demographic raise suspicion possible rubella i...</td>\n",
       "      <td>22.0</td>\n",
       "      <td>U</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>What bacterial infection can lead to the devel...</td>\n",
       "      <td>non-urgent</td>\n",
       "      <td>bacterial infection lead development risus sar...</td>\n",
       "      <td>22.0</td>\n",
       "      <td>U</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Hi my daughter is two years old and lately she...</td>\n",
       "      <td>urgent</td>\n",
       "      <td>daughter year old lately loose stool black col...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>I have a large anechoic cyst in my right kidne...</td>\n",
       "      <td>non-urgent</td>\n",
       "      <td>large anechoic cyst right kidney year reach 10...</td>\n",
       "      <td>13.0</td>\n",
       "      <td>U</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>What is the patella reflex and which nerve roo...</td>\n",
       "      <td>non-urgent</td>\n",
       "      <td>patella reflex nerve root test</td>\n",
       "      <td>22.0</td>\n",
       "      <td>U</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Hello doctor, I am 42 years old. I had a heart...</td>\n",
       "      <td>non-urgent</td>\n",
       "      <td>doctor 42 year old heart attack 12 year ago st...</td>\n",
       "      <td>42.0</td>\n",
       "      <td>U</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question      triage  \\\n",
       "0  I am 35 years old unmarried , i was diagonized...  non-urgent   \n",
       "1  I have been having abdominal pain and burning ...  non-urgent   \n",
       "2  sir, Day before yesterday i had an oil fried i...      urgent   \n",
       "3  friend has a lump where their coccyx is, has b...      urgent   \n",
       "4  Which demographic should raise suspicion of a ...  non-urgent   \n",
       "5  What bacterial infection can lead to the devel...  non-urgent   \n",
       "6  Hi my daughter is two years old and lately she...      urgent   \n",
       "7  I have a large anechoic cyst in my right kidne...  non-urgent   \n",
       "8  What is the patella reflex and which nerve roo...  non-urgent   \n",
       "9  Hello doctor, I am 42 years old. I had a heart...  non-urgent   \n",
       "\n",
       "                                      question_clean   age sex  label  \n",
       "0  35 year old unmarried diagonize hepatitis b su...  35.0   U      0  \n",
       "1  abdominal pain burn no relieve omeprazole bowe...  22.0   U      0  \n",
       "2  sir day yesterday oil fry item snack chappathi...  22.0   M      1  \n",
       "3  friend lump coccyx complete agony literally sc...  22.0   U      1  \n",
       "4  demographic raise suspicion possible rubella i...  22.0   U      0  \n",
       "5  bacterial infection lead development risus sar...  22.0   U      0  \n",
       "6  daughter year old lately loose stool black col...   2.0   F      1  \n",
       "7  large anechoic cyst right kidney year reach 10...  13.0   U      0  \n",
       "8                     patella reflex nerve root test  22.0   U      0  \n",
       "9  doctor 42 year old heart attack 12 year ago st...  42.0   U      0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e7d8356c-f311-40cb-88e8-b229043bdafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== Construction du texte d'entrée BERT ====\n",
    "def build_input(row):\n",
    "    text = row['question_clean']\n",
    "    age = int(row['age']) if not pd.isnull(row['age']) else \"unknown\"\n",
    "    sex = row['sex'] if row['sex'] != \"U\" else \"unknown\"\n",
    "    return f\"Age: {age}; Sex: {sex}; Symptoms: {text}\"\n",
    "\n",
    "df['input_text'] = df.apply(build_input, axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0e68ca1b-b532-47dd-a8f7-ccbeb56e7fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== Split Train/Test ====\n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
    "    df['input_text'], df['label'], test_size=0.2, stratify=df['label'], random_state=SEED\n",
    ")\n",
    "\n",
    "# ==== Dataset HuggingFace ====\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "class TriageDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_len=128):\n",
    "        self.encodings = tokenizer(texts.tolist(), padding=True, truncation=True, max_length=max_len)\n",
    "        self.labels = labels.tolist()\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "train_dataset = TriageDataset(train_texts, train_labels, tokenizer, MAX_LEN)\n",
    "test_dataset = TriageDataset(test_texts, test_labels, tokenizer, MAX_LEN)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "beb47bc0-d6c2-487e-af48-36e09383f793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ GPU NON disponible, uniquement CPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"✅ GPU disponible :\", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print(\"❌ GPU NON disponible, uniquement CPU\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1fc63af5-98e4-41b5-9886-4e8c0b25b4c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at emilyalsentzer/Bio_ClinicalBERT and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/anaconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='13473' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [    3/13473 00:03 < 12:45:01, 0.29 it/s, Epoch 0.00/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 23\u001b[0m\n\u001b[1;32m      4\u001b[0m training_args \u001b[38;5;241m=\u001b[39m TrainingArguments(\n\u001b[1;32m      5\u001b[0m     output_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./results\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      6\u001b[0m     num_train_epochs\u001b[38;5;241m=\u001b[39mEPOCHS,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m     seed\u001b[38;5;241m=\u001b[39mSEED\n\u001b[1;32m     14\u001b[0m )\n\u001b[1;32m     16\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m     17\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     18\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[1;32m     19\u001b[0m     train_dataset\u001b[38;5;241m=\u001b[39mtrain_dataset,\n\u001b[1;32m     20\u001b[0m     eval_dataset\u001b[38;5;241m=\u001b[39mtest_dataset,\n\u001b[1;32m     21\u001b[0m )\n\u001b[0;32m---> 23\u001b[0m trainer\u001b[38;5;241m.\u001b[39mtrain()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/transformers/trainer.py:2240\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2238\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2239\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2240\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m inner_training_loop(\n\u001b[1;32m   2241\u001b[0m         args\u001b[38;5;241m=\u001b[39margs,\n\u001b[1;32m   2242\u001b[0m         resume_from_checkpoint\u001b[38;5;241m=\u001b[39mresume_from_checkpoint,\n\u001b[1;32m   2243\u001b[0m         trial\u001b[38;5;241m=\u001b[39mtrial,\n\u001b[1;32m   2244\u001b[0m         ignore_keys_for_eval\u001b[38;5;241m=\u001b[39mignore_keys_for_eval,\n\u001b[1;32m   2245\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/transformers/trainer.py:2555\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2548\u001b[0m context \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   2549\u001b[0m     functools\u001b[38;5;241m.\u001b[39mpartial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mno_sync, model\u001b[38;5;241m=\u001b[39mmodel)\n\u001b[1;32m   2550\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch_samples) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   2551\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mdistributed_type \u001b[38;5;241m!=\u001b[39m DistributedType\u001b[38;5;241m.\u001b[39mDEEPSPEED\n\u001b[1;32m   2552\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m contextlib\u001b[38;5;241m.\u001b[39mnullcontext\n\u001b[1;32m   2553\u001b[0m )\n\u001b[1;32m   2554\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[0;32m-> 2555\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_step(model, inputs, num_items_in_batch)\n\u001b[1;32m   2557\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2558\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2559\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[1;32m   2560\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   2561\u001b[0m ):\n\u001b[1;32m   2562\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2563\u001b[0m     tr_loss \u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m+\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/transformers/trainer.py:3791\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   3788\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mdistributed_type \u001b[38;5;241m==\u001b[39m DistributedType\u001b[38;5;241m.\u001b[39mDEEPSPEED:\n\u001b[1;32m   3789\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscale_wrt_gas\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m-> 3791\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mbackward(loss, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   3793\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\u001b[38;5;241m.\u001b[39mdetach()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/accelerate/accelerator.py:2473\u001b[0m, in \u001b[0;36mAccelerator.backward\u001b[0;34m(self, loss, **kwargs)\u001b[0m\n\u001b[1;32m   2471\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlomo_backward(loss, learning_rate)\n\u001b[1;32m   2472\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2473\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/_tensor.py:648\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    638\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    639\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    640\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    641\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    646\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    647\u001b[0m     )\n\u001b[0;32m--> 648\u001b[0m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mbackward(\n\u001b[1;32m    649\u001b[0m     \u001b[38;5;28mself\u001b[39m, gradient, retain_graph, create_graph, inputs\u001b[38;5;241m=\u001b[39minputs\n\u001b[1;32m    650\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/autograd/__init__.py:353\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    348\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    350\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    351\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 353\u001b[0m _engine_run_backward(\n\u001b[1;32m    354\u001b[0m     tensors,\n\u001b[1;32m    355\u001b[0m     grad_tensors_,\n\u001b[1;32m    356\u001b[0m     retain_graph,\n\u001b[1;32m    357\u001b[0m     create_graph,\n\u001b[1;32m    358\u001b[0m     inputs,\n\u001b[1;32m    359\u001b[0m     allow_unreachable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    360\u001b[0m     accumulate_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    361\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/autograd/graph.py:824\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    822\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    823\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 824\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    825\u001b[0m         t_outputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    826\u001b[0m     )  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    827\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    828\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# ==== Modèle & entraînement ====\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=2)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=EPOCHS,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"no\",\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=20,\n",
    "    seed=SEED\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    ")\n",
    "\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23147ebd-71ae-4700-8c77-80b23186593e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== Prédiction & évaluation ====\n",
    "preds = trainer.predict(test_dataset)\n",
    "y_pred = np.argmax(preds.predictions, axis=1)\n",
    "print(classification_report(test_labels, y_pred, target_names=['non-urgent', 'urgent']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e258a8-bb38-408a-8a97-1dd1e2fdd46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== Courbes ROC et PR ====\n",
    "y_prob = torch.nn.functional.softmax(torch.tensor(preds.predictions), dim=1)[:,1].numpy()\n",
    "fpr, tpr, _ = roc_curve(test_labels, y_prob)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure(figsize=(7,5))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=1, linestyle='--')\n",
    "plt.xlabel('Taux de faux positifs (1-Spécificité)')\n",
    "plt.ylabel('Taux de vrais positifs (Sensibilité)')\n",
    "plt.title('Courbe ROC - Modèle de triage urgence (BERT)')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "cm = confusion_matrix(test_labels, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"Non-urgent\", \"Urgent\"])\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title('Matrice de confusion')\n",
    "plt.show()\n",
    "\n",
    "precision, recall, thresholds = precision_recall_curve(test_labels, y_prob)\n",
    "avg_prec = average_precision_score(test_labels, y_prob)\n",
    "\n",
    "plt.figure(figsize=(7,5))\n",
    "plt.plot(recall, precision, color='purple', lw=2, label=f'Courbe PR (AP={avg_prec:.2f})')\n",
    "plt.xlabel('Recall (Sensibilité)')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Courbe Precision-Recall - Modèle de triage urgence (BERT)')\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
